{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: NER\n",
    "**NER** = Named entity recognition <br>\n",
    "This is an NLP task to identify important named entities in the text\n",
    "<ul>\n",
    "<li>People, places, organizations\n",
    "<li>Dates, states, works of art\n",
    "<li>... and other categories!\n",
    "</ul>\n",
    "Can be used alongside topic identification\n",
    "... or on its own!\n",
    "It answer questions such as Who? What? When? Where?<br>\n",
    "NER can be used to achieve <b>fact extraction</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>Standard CoreNLP Library </b> supports NER. It also created dependency trees to find relationships between words.<br>\n",
    "We are going to use the spacy library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Using nltk for NER </h>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use spacy, it is necessary to download a language model to work with. In this notebook we will use English as our language model. To download it, open a terminal an type:\n",
    "\n",
    "* `python -m spacy download en_core_web_sm`\n",
    "\n",
    "for more information about langages and models see: https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the text to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"One of the more understated but intriguing statements in Zuckerberg’s \\\n",
    "Vox interview this past Monday was his public acknowledgment at long last that\\\n",
    "the company uses computer algorithms to scan all of our private communications\\\n",
    "on its platform, including Facebook Messenger.\\\n",
    "While users could always manually report threatening or illegal behavior and \\\n",
    "communications for human review, Zuckerberg acknowledged for the first time that\\\n",
    "even in private chat sessions, Facebook is not actually a neutral communications \\\n",
    "platform like the phone company that just provides you a connection and goes away \\\n",
    "– Facebook’s algorithms are there constantly monitoring your most private intimate\\\n",
    "conversations in an Orwellian telescreen that never turns off.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert the text into a spacy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore the named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One : CARDINAL\n",
      "Zuckerberg : PERSON\n",
      "Vox : PERSON\n",
      "this past Monday : DATE\n",
      "Facebook Messenger : PERSON\n",
      "Zuckerberg : PERSON\n",
      "first : ORDINAL\n",
      "Facebook : ORG\n",
      "Facebook : ORG\n",
      "Orwellian : NORP\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text,':',ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
